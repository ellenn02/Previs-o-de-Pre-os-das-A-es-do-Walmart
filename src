# Importando bibliotecas necessárias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import gdown
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from math import sqrt

# URL do arquivo no Google Drive
url = 'https://drive.google.com/uc?id=13SQ1N3PZtieiaVr37aK5rA8mcuQYMEHA'  # ID do arquivo extraído da URL original
output = 'Walmart_stock_data.csv'

# Baixando o arquivo diretamente do Google Drive
gdown.download(url, output, quiet=False)

# Carregando os dados de preços das ações
df = pd.read_csv(output)

# Convertendo a coluna 'Date' para o formato de data
df['Date'] = pd.to_datetime(df['Date'])

# Definindo a coluna 'Date' como o índice
df.set_index('Date', inplace=True)

# Exibindo as primeiras linhas dos dados
print(df.head())

# Plotando os preços de fechamento ao longo do tempo
plt.figure(figsize=(10, 6))
plt.plot(df['Adj Close'], label='Preço Ajustado de Fechamento')
plt.title('Preços Ajustados de Fechamento das Ações do Walmart')
plt.xlabel('Data')
plt.ylabel('Preço Ajustado de Fechamento')
plt.legend()
plt.grid()
plt.show()

# Dividindo os dados em treino e teste
train_size = int(len(df) * 0.8)
train, test = df['Adj Close'][:train_size], df['Adj Close'][train_size:]

# Construindo o modelo ARIMA
model = ARIMA(train, order=(5, 1, 0))  # Parâmetros (p, d, q) do ARIMA
model_fit = model.fit()

# Fazendo previsões
predictions = model_fit.forecast(steps=len(test))

# Plotando os resultados
plt.figure(figsize=(10, 6))
plt.plot(train.index, train, label='Treino')
plt.plot(test.index, test, label='Teste', color='orange')
plt.plot(test.index, predictions, label='Previsões', color='green')
plt.title('Previsão de Preços das Ações do Walmart')
plt.xlabel('Data')
plt.ylabel('Preço Ajustado de Fechamento')
plt.legend()
plt.grid()
plt.show()

# Calculando o erro da previsão (RMSE)
rmse = sqrt(mean_squared_error(test, predictions))
print(f'Erro Quadrático Médio da Previsão (RMSE): {rmse}')
